{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "from utils.Perspectiver import Perspectiver\n",
    "from utils.Loader import CardsDataset\n",
    "from arquitecture.CardsClassifier import CardClassifier\n",
    "from arquitecture.SupraCardClassifier import SupraCardClassifier\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Currently using\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset scale testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CardsDataset().data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_1 = 1\n",
    "scale_2 = 0.60\n",
    "dataset_scale_100 = CardsDataset(scale=scale_1)\n",
    "dataset_scale_050 = CardsDataset(scale=scale_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "idx = random.randint(0, len(dataset_scale_050))\n",
    "img_1 , label_1 = dataset_scale_100.__getitem__(idx)\n",
    "img_2 , label_2 = dataset_scale_050.__getitem__(idx)\n",
    "Perspectiver.plotComparison(imageBefore = Perspectiver.grayscale_to_rgb(img_1.numpy()[0]) , \n",
    "                            imageAfter = Perspectiver.grayscale_to_rgb(img_2.numpy()[0]) , \n",
    "                            titleBefore = f\"{dataset_scale_100.decode_label(label_1)} {scale_1*100}% {img_1.size()} \",\n",
    "                            titleAfter = f\"{dataset_scale_050.decode_label(label_2)} {scale_2*100}% {img_2.size()} \"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "BATCH_SIZE = 600\n",
    "NUN_WORKERS = 8\n",
    "LR = 0.003\n",
    "SEED = 555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_torch_seed(seed: int = 555):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_torch_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, epoch, optimizer, loss, name):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }, f\"models/checkpoints/{name}.pth\")\n",
    "\n",
    "def validation(model, valid_loader, criterion, device):\n",
    "        valid_loss = 0.0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valid_loader:\n",
    "                outputs = model(inputs.to(device))\n",
    "                loss = criterion(outputs, torch.argmax(labels.to(device), dim=1))\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                x, preds = torch.max(outputs, dim=1)\n",
    "                correct += (preds == torch.argmax(labels.to(device), dim=1)).sum().item()\n",
    "        \n",
    "        valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "        valid_prec = correct / len(valid_loader.dataset)\n",
    "\n",
    "        return valid_loss, valid_prec\n",
    "    \n",
    "def training(model, optimizer, criterion, train_loader, valid_loader, name, device, epochs):\n",
    "    max_prec = 0\n",
    "    train_loss_record = []\n",
    "    valid_loss_record = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.to(device))\n",
    "            loss = criterion(outputs, torch.argmax(labels.to(device), dim=1))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        model.eval()\n",
    "        \n",
    "        valid_loss, valid_prec = validation(model, valid_loader, criterion, device)\n",
    "        if valid_prec > max_prec:\n",
    "            save_checkpoint(model, epoch, optimizer, loss, name)\n",
    "            max_prec = valid_prec\n",
    "        \n",
    "        train_loss_record.append(train_loss)\n",
    "        valid_loss_record.append(valid_loss)\n",
    "        print(f\"EPOCH {epoch+1}/{epochs} - Training Loss: {train_loss:.4f} - Validation Loss: {valid_loss:.4f} - Validation Precision: {valid_prec:.4f}\")\n",
    "        \n",
    "    return train_loss_record, valid_loss_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256845\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"cards.csv\"\n",
    "target = \"suit\"\n",
    "\n",
    "train_dataset = CardsDataset(scale=0.6, split=\"train\", csv_file=csv_file, target=target)\n",
    "test_dataset = CardsDataset(scale=0.6, split=\"test\", csv_file=csv_file, target=target)\n",
    "valid_dataset = CardsDataset(scale=0.6, split=\"valid\", csv_file=csv_file, target=target)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUN_WORKERS)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUN_WORKERS)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=True, num_workers=NUN_WORKERS)\n",
    "\n",
    "_, label = test_dataset.__getitem__(1)\n",
    "\n",
    "classifier = CardClassifier(image_size=torch.Size((134, 134)), \n",
    "                            convolution_structure=[1,8,8,16,16,24,24,32,32],\n",
    "                            expert_output_len=3,\n",
    "                            expert_depth=4,\n",
    "                            output_len=len(label),\n",
    "                            pool_depth=2\n",
    "                            ).to(DEVICE)\n",
    "\n",
    "\n",
    "print(classifier.n_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction = \"mean\")\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=LR)\n",
    "\n",
    "os.makedirs(f\"models/checkpoints/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/100 - Training Loss: 1.3867 - Validation Loss: 1.3873 - Validation Precision: 0.2500\n",
      "EPOCH 2/100 - Training Loss: 1.3331 - Validation Loss: 1.3925 - Validation Precision: 0.2500\n",
      "EPOCH 3/100 - Training Loss: 1.2606 - Validation Loss: 1.3610 - Validation Precision: 0.2500\n",
      "EPOCH 4/100 - Training Loss: 1.2138 - Validation Loss: 1.4064 - Validation Precision: 0.3654\n",
      "EPOCH 5/100 - Training Loss: 1.1718 - Validation Loss: 1.7952 - Validation Precision: 0.3077\n",
      "EPOCH 6/100 - Training Loss: 1.0955 - Validation Loss: 6.0639 - Validation Precision: 0.3962\n",
      "EPOCH 7/100 - Training Loss: 1.0218 - Validation Loss: 3.7165 - Validation Precision: 0.4500\n",
      "EPOCH 8/100 - Training Loss: 0.9485 - Validation Loss: 19.2050 - Validation Precision: 0.2500\n",
      "EPOCH 9/100 - Training Loss: 0.8941 - Validation Loss: 13.4885 - Validation Precision: 0.2500\n",
      "EPOCH 10/100 - Training Loss: 0.8068 - Validation Loss: 2.5495 - Validation Precision: 0.2769\n",
      "EPOCH 11/100 - Training Loss: 0.7753 - Validation Loss: 2.3107 - Validation Precision: 0.4346\n",
      "EPOCH 12/100 - Training Loss: 0.6930 - Validation Loss: 4.7524 - Validation Precision: 0.2923\n",
      "EPOCH 13/100 - Training Loss: 0.6443 - Validation Loss: 1.3691 - Validation Precision: 0.2885\n",
      "EPOCH 14/100 - Training Loss: 0.5727 - Validation Loss: 0.5900 - Validation Precision: 0.7962\n",
      "EPOCH 15/100 - Training Loss: 0.5408 - Validation Loss: 3.9703 - Validation Precision: 0.2500\n",
      "EPOCH 16/100 - Training Loss: 0.4307 - Validation Loss: 1.9028 - Validation Precision: 0.5885\n",
      "EPOCH 17/100 - Training Loss: 0.3954 - Validation Loss: 2.9807 - Validation Precision: 0.4423\n",
      "EPOCH 18/100 - Training Loss: 0.3413 - Validation Loss: 0.4121 - Validation Precision: 0.8385\n",
      "EPOCH 19/100 - Training Loss: 0.3130 - Validation Loss: 0.5752 - Validation Precision: 0.7962\n",
      "EPOCH 20/100 - Training Loss: 0.3042 - Validation Loss: 2.8034 - Validation Precision: 0.3769\n",
      "EPOCH 21/100 - Training Loss: 0.2858 - Validation Loss: 1.8723 - Validation Precision: 0.2923\n",
      "EPOCH 22/100 - Training Loss: 0.2709 - Validation Loss: 0.7780 - Validation Precision: 0.6808\n",
      "EPOCH 23/100 - Training Loss: 0.2476 - Validation Loss: 0.9756 - Validation Precision: 0.7077\n",
      "EPOCH 24/100 - Training Loss: 0.2365 - Validation Loss: 0.9671 - Validation Precision: 0.6346\n",
      "EPOCH 25/100 - Training Loss: 0.2378 - Validation Loss: 0.5153 - Validation Precision: 0.8385\n",
      "EPOCH 26/100 - Training Loss: 0.2266 - Validation Loss: 0.9117 - Validation Precision: 0.6538\n",
      "EPOCH 27/100 - Training Loss: 0.2060 - Validation Loss: 1.7452 - Validation Precision: 0.7000\n",
      "EPOCH 28/100 - Training Loss: 0.1989 - Validation Loss: 1.1354 - Validation Precision: 0.6231\n",
      "EPOCH 29/100 - Training Loss: 0.1845 - Validation Loss: 0.9569 - Validation Precision: 0.7500\n",
      "EPOCH 30/100 - Training Loss: 0.1802 - Validation Loss: 0.8681 - Validation Precision: 0.7269\n",
      "EPOCH 31/100 - Training Loss: 0.1693 - Validation Loss: 0.7907 - Validation Precision: 0.8192\n",
      "EPOCH 32/100 - Training Loss: 0.1719 - Validation Loss: 0.5466 - Validation Precision: 0.7385\n",
      "EPOCH 33/100 - Training Loss: 0.1605 - Validation Loss: 0.2870 - Validation Precision: 0.9038\n",
      "EPOCH 34/100 - Training Loss: 0.1585 - Validation Loss: 1.9176 - Validation Precision: 0.5885\n",
      "EPOCH 35/100 - Training Loss: 0.1452 - Validation Loss: 0.1912 - Validation Precision: 0.9269\n",
      "EPOCH 36/100 - Training Loss: 0.1367 - Validation Loss: 8.9108 - Validation Precision: 0.3346\n",
      "EPOCH 37/100 - Training Loss: 0.1312 - Validation Loss: 1.1243 - Validation Precision: 0.6500\n",
      "EPOCH 38/100 - Training Loss: 0.1376 - Validation Loss: 3.8199 - Validation Precision: 0.5769\n",
      "EPOCH 39/100 - Training Loss: 0.1418 - Validation Loss: 0.6626 - Validation Precision: 0.7385\n",
      "EPOCH 40/100 - Training Loss: 0.1444 - Validation Loss: 4.1830 - Validation Precision: 0.3615\n",
      "EPOCH 41/100 - Training Loss: 0.1283 - Validation Loss: 0.4777 - Validation Precision: 0.8500\n",
      "EPOCH 42/100 - Training Loss: 0.1093 - Validation Loss: 0.4492 - Validation Precision: 0.8846\n",
      "EPOCH 43/100 - Training Loss: 0.0990 - Validation Loss: 0.6129 - Validation Precision: 0.8154\n",
      "EPOCH 44/100 - Training Loss: 0.0958 - Validation Loss: 0.4046 - Validation Precision: 0.8923\n",
      "EPOCH 45/100 - Training Loss: 0.0893 - Validation Loss: 1.8004 - Validation Precision: 0.7308\n",
      "EPOCH 46/100 - Training Loss: 0.0868 - Validation Loss: 0.5015 - Validation Precision: 0.8231\n",
      "EPOCH 47/100 - Training Loss: 0.0787 - Validation Loss: 0.4504 - Validation Precision: 0.9000\n",
      "EPOCH 48/100 - Training Loss: 0.0768 - Validation Loss: 1.1041 - Validation Precision: 0.6538\n",
      "EPOCH 49/100 - Training Loss: 0.0747 - Validation Loss: 0.2006 - Validation Precision: 0.9154\n",
      "EPOCH 50/100 - Training Loss: 0.0844 - Validation Loss: 0.4112 - Validation Precision: 0.9231\n",
      "EPOCH 51/100 - Training Loss: 0.0910 - Validation Loss: 0.9238 - Validation Precision: 0.7923\n",
      "EPOCH 52/100 - Training Loss: 0.0955 - Validation Loss: 1.7479 - Validation Precision: 0.6500\n",
      "EPOCH 53/100 - Training Loss: 0.0922 - Validation Loss: 1.1569 - Validation Precision: 0.8231\n",
      "EPOCH 54/100 - Training Loss: 0.0938 - Validation Loss: 0.3607 - Validation Precision: 0.8462\n",
      "EPOCH 55/100 - Training Loss: 0.0748 - Validation Loss: 0.2245 - Validation Precision: 0.9231\n",
      "EPOCH 56/100 - Training Loss: 0.0643 - Validation Loss: 0.2121 - Validation Precision: 0.9462\n",
      "EPOCH 57/100 - Training Loss: 0.0602 - Validation Loss: 0.6832 - Validation Precision: 0.8731\n",
      "EPOCH 58/100 - Training Loss: 0.0512 - Validation Loss: 0.8922 - Validation Precision: 0.7308\n",
      "EPOCH 59/100 - Training Loss: 0.0551 - Validation Loss: 0.6276 - Validation Precision: 0.8615\n",
      "EPOCH 60/100 - Training Loss: 0.0437 - Validation Loss: 0.2246 - Validation Precision: 0.9385\n",
      "EPOCH 61/100 - Training Loss: 0.0345 - Validation Loss: 0.2592 - Validation Precision: 0.9231\n",
      "EPOCH 62/100 - Training Loss: 0.0312 - Validation Loss: 0.1855 - Validation Precision: 0.9538\n",
      "EPOCH 63/100 - Training Loss: 0.0370 - Validation Loss: 0.4729 - Validation Precision: 0.8885\n",
      "EPOCH 64/100 - Training Loss: 0.0383 - Validation Loss: 1.5957 - Validation Precision: 0.7269\n",
      "EPOCH 65/100 - Training Loss: 0.0518 - Validation Loss: 5.5044 - Validation Precision: 0.3654\n",
      "EPOCH 66/100 - Training Loss: 0.0742 - Validation Loss: 0.4483 - Validation Precision: 0.9269\n",
      "EPOCH 67/100 - Training Loss: 0.0644 - Validation Loss: 0.3196 - Validation Precision: 0.8769\n",
      "EPOCH 68/100 - Training Loss: 0.0619 - Validation Loss: 0.2891 - Validation Precision: 0.9192\n",
      "EPOCH 69/100 - Training Loss: 0.0547 - Validation Loss: 0.3213 - Validation Precision: 0.9462\n",
      "EPOCH 70/100 - Training Loss: 0.0458 - Validation Loss: 0.6273 - Validation Precision: 0.8615\n",
      "EPOCH 71/100 - Training Loss: 0.0399 - Validation Loss: 0.4013 - Validation Precision: 0.8577\n",
      "EPOCH 72/100 - Training Loss: 0.0398 - Validation Loss: 1.9959 - Validation Precision: 0.6923\n",
      "EPOCH 73/100 - Training Loss: 0.0459 - Validation Loss: 2.0101 - Validation Precision: 0.7577\n",
      "EPOCH 74/100 - Training Loss: 0.0469 - Validation Loss: 0.4548 - Validation Precision: 0.8923\n",
      "EPOCH 75/100 - Training Loss: 0.0440 - Validation Loss: 0.2406 - Validation Precision: 0.9115\n",
      "EPOCH 76/100 - Training Loss: 0.0365 - Validation Loss: 0.7948 - Validation Precision: 0.8538\n",
      "EPOCH 77/100 - Training Loss: 0.0324 - Validation Loss: 0.1964 - Validation Precision: 0.9538\n",
      "EPOCH 78/100 - Training Loss: 0.0256 - Validation Loss: 0.2814 - Validation Precision: 0.9423\n",
      "EPOCH 79/100 - Training Loss: 0.0248 - Validation Loss: 0.1667 - Validation Precision: 0.9615\n",
      "EPOCH 80/100 - Training Loss: 0.0231 - Validation Loss: 0.3660 - Validation Precision: 0.8885\n",
      "EPOCH 81/100 - Training Loss: 0.0203 - Validation Loss: 0.4372 - Validation Precision: 0.9115\n",
      "EPOCH 82/100 - Training Loss: 0.0222 - Validation Loss: 0.4870 - Validation Precision: 0.8846\n",
      "EPOCH 83/100 - Training Loss: 0.0206 - Validation Loss: 0.1820 - Validation Precision: 0.9423\n",
      "EPOCH 84/100 - Training Loss: 0.0225 - Validation Loss: 1.8662 - Validation Precision: 0.7231\n",
      "EPOCH 85/100 - Training Loss: 0.0215 - Validation Loss: 1.0733 - Validation Precision: 0.7769\n",
      "EPOCH 86/100 - Training Loss: 0.0268 - Validation Loss: 0.7053 - Validation Precision: 0.8731\n",
      "EPOCH 87/100 - Training Loss: 0.0351 - Validation Loss: 0.2216 - Validation Precision: 0.9577\n",
      "EPOCH 88/100 - Training Loss: 0.0392 - Validation Loss: 1.9502 - Validation Precision: 0.7769\n",
      "EPOCH 89/100 - Training Loss: 0.0563 - Validation Loss: 0.5423 - Validation Precision: 0.8731\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_loss_record, valid_loss_record = \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m         \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m         \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m         \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m         \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m         \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msuit_classifier_checkpoint\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m         \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCH\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m     12\u001b[39m plt.plot(train_loss_record, label=\u001b[33m\"\u001b[39m\u001b[33mTraining Loss\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mtraining\u001b[39m\u001b[34m(model, optimizer, criterion, train_loader, valid_loader, name, device, epochs)\u001b[39m\n\u001b[32m     44\u001b[39m train_loss = train_loss / \u001b[38;5;28mlen\u001b[39m(train_loader.dataset)\n\u001b[32m     45\u001b[39m model.eval()\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m valid_loss, valid_prec = \u001b[43mvalidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid_prec > max_prec:\n\u001b[32m     49\u001b[39m     save_checkpoint(model, epoch, optimizer, loss, name)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mvalidation\u001b[39m\u001b[34m(model, valid_loader, criterion, device)\u001b[39m\n\u001b[32m     11\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/venvs/pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/venvs/pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/venvs/pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1453\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1449\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1450\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1451\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1452\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1453\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1454\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1455\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/venvs/pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1287\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    112\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:440\u001b[39m, in \u001b[36mConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     r = \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:1136\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1133\u001b[39m     deadline = time.monotonic() + timeout\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1136\u001b[39m     ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [key.fileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_loss_record, valid_loss_record = training(model=classifier, \n",
    "         optimizer=optimizer, \n",
    "         criterion=criterion,\n",
    "         train_loader=train_loader,\n",
    "         valid_loader=valid_loader,\n",
    "         name=\"suit_classifier_checkpoint\",\n",
    "         device=DEVICE,\n",
    "         epochs=EPOCH\n",
    "         )\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss_record, label=\"Training Loss\")\n",
    "plt.plot(valid_loss_record, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss History\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259058\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"cards.csv\"\n",
    "target = \"category\"\n",
    "\n",
    "train_dataset = CardsDataset(scale=0.6, split=\"train\", csv_file=csv_file, target=target)\n",
    "test_dataset = CardsDataset(scale=0.6, split=\"test\", csv_file=csv_file, target=target)\n",
    "valid_dataset = CardsDataset(scale=0.6, split=\"valid\", csv_file=csv_file, target=target)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUN_WORKERS)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUN_WORKERS)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=True, num_workers=NUN_WORKERS)\n",
    "\n",
    "_, label = test_dataset.__getitem__(1)\n",
    "\n",
    "classifier = CardClassifier(image_size=torch.Size((134, 134)), \n",
    "                            convolution_structure=[1,12,12,16,16,24,24,32,32],\n",
    "                            expert_output_len=3, # 3  -> 0.7\n",
    "                            expert_depth=5,\n",
    "                            output_len=len(label),\n",
    "                            pool_depth=2\n",
    "                            ).to(DEVICE)\n",
    "\n",
    "print(classifier.n_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/200 - Training Loss: 2.5227 - Validation Loss: 2.5650 - Validation Precision: 0.0769\n",
      "EPOCH 2/200 - Training Loss: 2.4017 - Validation Loss: 2.5662 - Validation Precision: 0.0769\n",
      "EPOCH 3/200 - Training Loss: 2.3163 - Validation Loss: 2.5654 - Validation Precision: 0.0769\n",
      "EPOCH 4/200 - Training Loss: 2.2670 - Validation Loss: 2.5941 - Validation Precision: 0.1154\n",
      "EPOCH 5/200 - Training Loss: 2.1939 - Validation Loss: 2.5383 - Validation Precision: 0.1115\n",
      "EPOCH 6/200 - Training Loss: 2.1130 - Validation Loss: 2.5637 - Validation Precision: 0.2269\n",
      "EPOCH 7/200 - Training Loss: 2.0566 - Validation Loss: 2.3154 - Validation Precision: 0.2346\n",
      "EPOCH 8/200 - Training Loss: 1.9762 - Validation Loss: 2.7241 - Validation Precision: 0.2154\n",
      "EPOCH 9/200 - Training Loss: 1.9108 - Validation Loss: 2.1495 - Validation Precision: 0.2885\n",
      "EPOCH 10/200 - Training Loss: 1.8343 - Validation Loss: 2.1499 - Validation Precision: 0.2462\n",
      "EPOCH 11/200 - Training Loss: 1.7751 - Validation Loss: 1.6482 - Validation Precision: 0.4154\n",
      "EPOCH 12/200 - Training Loss: 1.7215 - Validation Loss: 1.7174 - Validation Precision: 0.3923\n",
      "EPOCH 13/200 - Training Loss: 1.6773 - Validation Loss: 1.7796 - Validation Precision: 0.4154\n",
      "EPOCH 14/200 - Training Loss: 1.5859 - Validation Loss: 1.6764 - Validation Precision: 0.4500\n",
      "EPOCH 15/200 - Training Loss: 1.4974 - Validation Loss: 1.5434 - Validation Precision: 0.5346\n",
      "EPOCH 16/200 - Training Loss: 1.4282 - Validation Loss: 1.3084 - Validation Precision: 0.5692\n",
      "EPOCH 17/200 - Training Loss: 1.3917 - Validation Loss: 1.4229 - Validation Precision: 0.5462\n",
      "EPOCH 18/200 - Training Loss: 1.3474 - Validation Loss: 1.1510 - Validation Precision: 0.6077\n",
      "EPOCH 19/200 - Training Loss: 1.3169 - Validation Loss: 1.1538 - Validation Precision: 0.6385\n",
      "EPOCH 20/200 - Training Loss: 1.3083 - Validation Loss: 1.2050 - Validation Precision: 0.6000\n",
      "EPOCH 21/200 - Training Loss: 1.2817 - Validation Loss: 1.0434 - Validation Precision: 0.6500\n",
      "EPOCH 22/200 - Training Loss: 1.2574 - Validation Loss: 1.0317 - Validation Precision: 0.6385\n",
      "EPOCH 23/200 - Training Loss: 1.2354 - Validation Loss: 1.2705 - Validation Precision: 0.6115\n",
      "EPOCH 24/200 - Training Loss: 1.2339 - Validation Loss: 1.0815 - Validation Precision: 0.6231\n",
      "EPOCH 25/200 - Training Loss: 1.2092 - Validation Loss: 1.0256 - Validation Precision: 0.6615\n",
      "EPOCH 26/200 - Training Loss: 1.1970 - Validation Loss: 1.1188 - Validation Precision: 0.6423\n",
      "EPOCH 27/200 - Training Loss: 1.1901 - Validation Loss: 1.5120 - Validation Precision: 0.5769\n",
      "EPOCH 28/200 - Training Loss: 1.1630 - Validation Loss: 1.0179 - Validation Precision: 0.6500\n",
      "EPOCH 29/200 - Training Loss: 1.1517 - Validation Loss: 1.0697 - Validation Precision: 0.6462\n",
      "EPOCH 30/200 - Training Loss: 1.1418 - Validation Loss: 1.1336 - Validation Precision: 0.6500\n",
      "EPOCH 31/200 - Training Loss: 1.1142 - Validation Loss: 1.0074 - Validation Precision: 0.6654\n",
      "EPOCH 32/200 - Training Loss: 1.0973 - Validation Loss: 0.9821 - Validation Precision: 0.6885\n",
      "EPOCH 33/200 - Training Loss: 1.0739 - Validation Loss: 1.0076 - Validation Precision: 0.7269\n",
      "EPOCH 34/200 - Training Loss: 1.0549 - Validation Loss: 1.0232 - Validation Precision: 0.7308\n",
      "EPOCH 35/200 - Training Loss: 1.0431 - Validation Loss: 1.1438 - Validation Precision: 0.7038\n",
      "EPOCH 36/200 - Training Loss: 0.9875 - Validation Loss: 0.8980 - Validation Precision: 0.7231\n",
      "EPOCH 37/200 - Training Loss: 0.9208 - Validation Loss: 0.6999 - Validation Precision: 0.7808\n",
      "EPOCH 38/200 - Training Loss: 0.8296 - Validation Loss: 1.0779 - Validation Precision: 0.7346\n",
      "EPOCH 39/200 - Training Loss: 0.8161 - Validation Loss: 0.7224 - Validation Precision: 0.7692\n",
      "EPOCH 40/200 - Training Loss: 0.7979 - Validation Loss: 0.8110 - Validation Precision: 0.7654\n",
      "EPOCH 41/200 - Training Loss: 0.7629 - Validation Loss: 0.6727 - Validation Precision: 0.7923\n",
      "EPOCH 42/200 - Training Loss: 0.7474 - Validation Loss: 1.0028 - Validation Precision: 0.7192\n",
      "EPOCH 43/200 - Training Loss: 0.7459 - Validation Loss: 0.7316 - Validation Precision: 0.8000\n",
      "EPOCH 44/200 - Training Loss: 0.7457 - Validation Loss: 0.7845 - Validation Precision: 0.7923\n",
      "EPOCH 45/200 - Training Loss: 0.7185 - Validation Loss: 0.6367 - Validation Precision: 0.8192\n",
      "EPOCH 46/200 - Training Loss: 0.6916 - Validation Loss: 0.7330 - Validation Precision: 0.7731\n",
      "EPOCH 47/200 - Training Loss: 0.6778 - Validation Loss: 0.6926 - Validation Precision: 0.7692\n",
      "EPOCH 48/200 - Training Loss: 0.6585 - Validation Loss: 0.7228 - Validation Precision: 0.7808\n",
      "EPOCH 49/200 - Training Loss: 0.6566 - Validation Loss: 0.7432 - Validation Precision: 0.8077\n",
      "EPOCH 50/200 - Training Loss: 0.6659 - Validation Loss: 0.8083 - Validation Precision: 0.7808\n",
      "EPOCH 51/200 - Training Loss: 0.6608 - Validation Loss: 0.7350 - Validation Precision: 0.8038\n",
      "EPOCH 52/200 - Training Loss: 0.6522 - Validation Loss: 0.8921 - Validation Precision: 0.7808\n",
      "EPOCH 53/200 - Training Loss: 0.6259 - Validation Loss: 0.8188 - Validation Precision: 0.7808\n",
      "EPOCH 54/200 - Training Loss: 0.6105 - Validation Loss: 0.7314 - Validation Precision: 0.7962\n",
      "EPOCH 55/200 - Training Loss: 0.6144 - Validation Loss: 0.9658 - Validation Precision: 0.7769\n",
      "EPOCH 56/200 - Training Loss: 0.6035 - Validation Loss: 0.8639 - Validation Precision: 0.7885\n",
      "EPOCH 57/200 - Training Loss: 0.5938 - Validation Loss: 0.7940 - Validation Precision: 0.8038\n",
      "EPOCH 58/200 - Training Loss: 0.5675 - Validation Loss: 0.6937 - Validation Precision: 0.8077\n",
      "EPOCH 59/200 - Training Loss: 0.5845 - Validation Loss: 0.6952 - Validation Precision: 0.8077\n",
      "EPOCH 60/200 - Training Loss: 0.5703 - Validation Loss: 0.8486 - Validation Precision: 0.7808\n",
      "EPOCH 61/200 - Training Loss: 0.5489 - Validation Loss: 0.8298 - Validation Precision: 0.7615\n",
      "EPOCH 62/200 - Training Loss: 0.5454 - Validation Loss: 0.7408 - Validation Precision: 0.8077\n",
      "EPOCH 63/200 - Training Loss: 0.5420 - Validation Loss: 0.6394 - Validation Precision: 0.8269\n",
      "EPOCH 64/200 - Training Loss: 0.5353 - Validation Loss: 0.8791 - Validation Precision: 0.7885\n",
      "EPOCH 65/200 - Training Loss: 0.5568 - Validation Loss: 0.9779 - Validation Precision: 0.7769\n",
      "EPOCH 66/200 - Training Loss: 0.5495 - Validation Loss: 1.5565 - Validation Precision: 0.7154\n",
      "EPOCH 67/200 - Training Loss: 0.5378 - Validation Loss: 0.8868 - Validation Precision: 0.7885\n",
      "EPOCH 68/200 - Training Loss: 0.5194 - Validation Loss: 0.8258 - Validation Precision: 0.8000\n",
      "EPOCH 69/200 - Training Loss: 0.5039 - Validation Loss: 0.7913 - Validation Precision: 0.7808\n",
      "EPOCH 70/200 - Training Loss: 0.5179 - Validation Loss: 0.6801 - Validation Precision: 0.8115\n",
      "EPOCH 71/200 - Training Loss: 0.4883 - Validation Loss: 0.8163 - Validation Precision: 0.7962\n",
      "EPOCH 72/200 - Training Loss: 0.4808 - Validation Loss: 0.9855 - Validation Precision: 0.7769\n",
      "EPOCH 73/200 - Training Loss: 0.4800 - Validation Loss: 0.7990 - Validation Precision: 0.8115\n",
      "EPOCH 74/200 - Training Loss: 0.4562 - Validation Loss: 0.7234 - Validation Precision: 0.8192\n",
      "EPOCH 75/200 - Training Loss: 0.4637 - Validation Loss: 0.7530 - Validation Precision: 0.8154\n",
      "EPOCH 76/200 - Training Loss: 0.4579 - Validation Loss: 0.9505 - Validation Precision: 0.7923\n",
      "EPOCH 77/200 - Training Loss: 0.4491 - Validation Loss: 0.9350 - Validation Precision: 0.8000\n",
      "EPOCH 78/200 - Training Loss: 0.4535 - Validation Loss: 0.8997 - Validation Precision: 0.7962\n",
      "EPOCH 79/200 - Training Loss: 0.4478 - Validation Loss: 0.8067 - Validation Precision: 0.8000\n",
      "EPOCH 80/200 - Training Loss: 0.4372 - Validation Loss: 0.9110 - Validation Precision: 0.8000\n",
      "EPOCH 81/200 - Training Loss: 0.4380 - Validation Loss: 0.8771 - Validation Precision: 0.7923\n",
      "EPOCH 82/200 - Training Loss: 0.4299 - Validation Loss: 0.8523 - Validation Precision: 0.7923\n",
      "EPOCH 83/200 - Training Loss: 0.4318 - Validation Loss: 0.9314 - Validation Precision: 0.7923\n",
      "EPOCH 84/200 - Training Loss: 0.4324 - Validation Loss: 0.7238 - Validation Precision: 0.7962\n",
      "EPOCH 85/200 - Training Loss: 0.4568 - Validation Loss: 0.9219 - Validation Precision: 0.8000\n",
      "EPOCH 86/200 - Training Loss: 0.4583 - Validation Loss: 0.9275 - Validation Precision: 0.7769\n",
      "EPOCH 87/200 - Training Loss: 0.4687 - Validation Loss: 1.3388 - Validation Precision: 0.7692\n",
      "EPOCH 88/200 - Training Loss: 0.4707 - Validation Loss: 0.9715 - Validation Precision: 0.7769\n",
      "EPOCH 89/200 - Training Loss: 0.4432 - Validation Loss: 0.7898 - Validation Precision: 0.8154\n",
      "EPOCH 90/200 - Training Loss: 0.4163 - Validation Loss: 0.9432 - Validation Precision: 0.7885\n",
      "EPOCH 91/200 - Training Loss: 0.4033 - Validation Loss: 0.8680 - Validation Precision: 0.8000\n",
      "EPOCH 92/200 - Training Loss: 0.3915 - Validation Loss: 0.7680 - Validation Precision: 0.8154\n",
      "EPOCH 93/200 - Training Loss: 0.3727 - Validation Loss: 0.8444 - Validation Precision: 0.8192\n",
      "EPOCH 94/200 - Training Loss: 0.3673 - Validation Loss: 0.9035 - Validation Precision: 0.7769\n",
      "EPOCH 95/200 - Training Loss: 0.3609 - Validation Loss: 0.8807 - Validation Precision: 0.8077\n",
      "EPOCH 96/200 - Training Loss: 0.3576 - Validation Loss: 0.8476 - Validation Precision: 0.8154\n",
      "EPOCH 97/200 - Training Loss: 0.3562 - Validation Loss: 0.9156 - Validation Precision: 0.8000\n",
      "EPOCH 98/200 - Training Loss: 0.3616 - Validation Loss: 0.9307 - Validation Precision: 0.8077\n",
      "EPOCH 99/200 - Training Loss: 0.3995 - Validation Loss: 1.1825 - Validation Precision: 0.7577\n",
      "EPOCH 100/200 - Training Loss: 0.4340 - Validation Loss: 1.0574 - Validation Precision: 0.8000\n",
      "EPOCH 101/200 - Training Loss: 0.4583 - Validation Loss: 1.1451 - Validation Precision: 0.7808\n",
      "EPOCH 102/200 - Training Loss: 0.4828 - Validation Loss: 1.2998 - Validation Precision: 0.7538\n",
      "EPOCH 103/200 - Training Loss: 0.4483 - Validation Loss: 0.9884 - Validation Precision: 0.7846\n",
      "EPOCH 104/200 - Training Loss: 0.4362 - Validation Loss: 0.7373 - Validation Precision: 0.7962\n",
      "EPOCH 105/200 - Training Loss: 0.3951 - Validation Loss: 0.8730 - Validation Precision: 0.8115\n",
      "EPOCH 106/200 - Training Loss: 0.3745 - Validation Loss: 0.8898 - Validation Precision: 0.7885\n",
      "EPOCH 107/200 - Training Loss: 0.3556 - Validation Loss: 0.7558 - Validation Precision: 0.8231\n",
      "EPOCH 108/200 - Training Loss: 0.3528 - Validation Loss: 0.9977 - Validation Precision: 0.8038\n",
      "EPOCH 109/200 - Training Loss: 0.3454 - Validation Loss: 0.8115 - Validation Precision: 0.8038\n",
      "EPOCH 110/200 - Training Loss: 0.3374 - Validation Loss: 0.8500 - Validation Precision: 0.8000\n",
      "EPOCH 111/200 - Training Loss: 0.3328 - Validation Loss: 0.8033 - Validation Precision: 0.8115\n",
      "EPOCH 112/200 - Training Loss: 0.3313 - Validation Loss: 0.9198 - Validation Precision: 0.8077\n",
      "EPOCH 113/200 - Training Loss: 0.3292 - Validation Loss: 0.8540 - Validation Precision: 0.8077\n",
      "EPOCH 114/200 - Training Loss: 0.3228 - Validation Loss: 0.8041 - Validation Precision: 0.8154\n",
      "EPOCH 115/200 - Training Loss: 0.3232 - Validation Loss: 1.1343 - Validation Precision: 0.7962\n",
      "EPOCH 116/200 - Training Loss: 0.3230 - Validation Loss: 1.0125 - Validation Precision: 0.8154\n",
      "EPOCH 117/200 - Training Loss: 0.3229 - Validation Loss: 1.1696 - Validation Precision: 0.7962\n",
      "EPOCH 118/200 - Training Loss: 0.3261 - Validation Loss: 1.2323 - Validation Precision: 0.8192\n",
      "EPOCH 119/200 - Training Loss: 0.3313 - Validation Loss: 1.0225 - Validation Precision: 0.8154\n",
      "EPOCH 120/200 - Training Loss: 0.3394 - Validation Loss: 0.9573 - Validation Precision: 0.8192\n",
      "EPOCH 121/200 - Training Loss: 0.3683 - Validation Loss: 1.3267 - Validation Precision: 0.7577\n",
      "EPOCH 122/200 - Training Loss: 0.4033 - Validation Loss: 0.9705 - Validation Precision: 0.7885\n",
      "EPOCH 123/200 - Training Loss: 0.3907 - Validation Loss: 1.2837 - Validation Precision: 0.7962\n",
      "EPOCH 124/200 - Training Loss: 0.3948 - Validation Loss: 0.9281 - Validation Precision: 0.8038\n",
      "EPOCH 125/200 - Training Loss: 0.4142 - Validation Loss: 0.9504 - Validation Precision: 0.7885\n",
      "EPOCH 126/200 - Training Loss: 0.3821 - Validation Loss: 0.9884 - Validation Precision: 0.8115\n",
      "EPOCH 127/200 - Training Loss: 0.3747 - Validation Loss: 0.8987 - Validation Precision: 0.8000\n",
      "EPOCH 128/200 - Training Loss: 0.3674 - Validation Loss: 1.1640 - Validation Precision: 0.7923\n",
      "EPOCH 129/200 - Training Loss: 0.3539 - Validation Loss: 0.8188 - Validation Precision: 0.8308\n",
      "EPOCH 130/200 - Training Loss: 0.3423 - Validation Loss: 0.9957 - Validation Precision: 0.8077\n",
      "EPOCH 131/200 - Training Loss: 0.3267 - Validation Loss: 0.9304 - Validation Precision: 0.8192\n",
      "EPOCH 132/200 - Training Loss: 0.3143 - Validation Loss: 0.8349 - Validation Precision: 0.8192\n",
      "EPOCH 133/200 - Training Loss: 0.3096 - Validation Loss: 1.0141 - Validation Precision: 0.8308\n",
      "EPOCH 134/200 - Training Loss: 0.3074 - Validation Loss: 1.1529 - Validation Precision: 0.7923\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m criterion = nn.CrossEntropyLoss(reduction = \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m optimizer = optim.Adam(classifier.parameters(), lr=LR)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m train_loss_record, valid_loss_record = \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m         \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m         \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m         \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m         \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m         \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcategory_classifier_checkpoint\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m         \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEPOCH\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Plotting the loss history\u001b[39;00m\n\u001b[32m     16\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mtraining\u001b[39m\u001b[34m(model, optimizer, criterion, train_loader, valid_loader, name, device, epochs)\u001b[39m\n\u001b[32m     39\u001b[39m     loss.backward()\n\u001b[32m     40\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * inputs.size(\u001b[32m0\u001b[39m)\n\u001b[32m     44\u001b[39m train_loss = train_loss / \u001b[38;5;28mlen\u001b[39m(train_loader.dataset)\n\u001b[32m     45\u001b[39m model.eval()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction = \"mean\")\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=LR)\n",
    "\n",
    "train_loss_record, valid_loss_record = training(model=classifier, \n",
    "         optimizer=optimizer, \n",
    "         criterion=criterion,\n",
    "         train_loader=train_loader,\n",
    "         valid_loader=valid_loader,\n",
    "         name=\"category_classifier_checkpoint\",\n",
    "         device=DEVICE,\n",
    "         epochs=(EPOCH*2)\n",
    "         )\n",
    "\n",
    "# Plotting the loss history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss_record, label=\"Training Loss\")\n",
    "plt.plot(valid_loss_record, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss History\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
