digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname="helvetica"] ;
edge [fontname="helvetica"] ;
0 [label=<expert_31_0 &le; 0.047<br/>entropy = 3.766<br/>samples = 530<br/>value = [40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40<br/>40, 10]<br/>class = 0>, fillcolor="#ffffff"] ;
1 [label=<expert_16_3 &le; 0.133<br/>entropy = 3.273<br/>samples = 289<br/>value = [35.0, 35.0, 39.0, 3.0, 6.0, 1.0, 33.0, 1.0, 38.0<br/>38.0, 7.0, 39.0, 5.0, 9.0]<br/>class = 2>, fillcolor="#ffffff"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<expert_0_1 &le; 0.188<br/>entropy = 2.342<br/>samples = 140<br/>value = [1, 34, 35, 1, 0, 0, 27, 0, 5, 34, 3, 0, 0, 0]<br/>class = 2>, fillcolor="#fefffd"] ;
1 -> 2 ;
3 [label=<expert_1_1 &le; 0.241<br/>entropy = 1.922<br/>samples = 99<br/>value = [1, 0, 35, 0, 0, 0, 23, 0, 3, 34, 3, 0, 0, 0]<br/>class = 2>, fillcolor="#fefffc"] ;
2 -> 3 ;
4 [label=<expert_1_0 &le; 0.549<br/>entropy = 1.082<br/>samples = 58<br/>value = [1, 0, 34, 0, 0, 0, 23, 0, 0, 0, 0, 0, 0, 0]<br/>class = 2>, fillcolor="#e8f7c1"] ;
3 -> 4 ;
5 [label=<entropy = 0.187<br/>samples = 35<br/>value = [1, 0, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = 2>, fillcolor="#b9e63f"] ;
4 -> 5 ;
6 [label=<entropy = 0.0<br/>samples = 23<br/>value = [0, 0, 0, 0, 0, 0, 23, 0, 0, 0, 0, 0, 0, 0]<br/>class = 6>, fillcolor="#39e5e2"] ;
4 -> 6 ;
7 [label=<expert_1_1 &le; 0.706<br/>entropy = 0.907<br/>samples = 41<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 3, 34, 3, 0, 0, 0]<br/>class = 9>, fillcolor="#835dea"] ;
3 -> 7 ;
8 [label=<entropy = 0.64<br/>samples = 25<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 2, 22, 1, 0, 0, 0]<br/>class = 9>, fillcolor="#7b53e8"] ;
7 -> 8 ;
9 [label=<entropy = 1.186<br/>samples = 16<br/>value = [0, 0, 1, 0, 0, 0, 0, 0, 1, 12, 2, 0, 0, 0]<br/>class = 9>, fillcolor="#9272ec"] ;
7 -> 9 ;
10 [label=<expert_0_3 &le; 0.452<br/>entropy = 0.895<br/>samples = 41<br/>value = [0, 34, 0, 1, 0, 0, 4, 0, 2, 0, 0, 0, 0, 0]<br/>class = 1>, fillcolor="#ead25e"] ;
2 -> 10 ;
11 [label=<entropy = 1.417<br/>samples = 20<br/>value = [0, 13, 0, 1, 0, 0, 4, 0, 2, 0, 0, 0, 0, 0]<br/>class = 1>, fillcolor="#f0e090"] ;
10 -> 11 ;
12 [label=<entropy = 0.0<br/>samples = 21<br/>value = [0, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = 1>, fillcolor="#e5c839"] ;
10 -> 12 ;
13 [label=<expert_5_1 &le; 0.547<br/>entropy = 2.906<br/>samples = 149<br/>value = [34, 1, 4, 2, 6, 1, 6, 1, 33, 4, 4, 39, 5, 9]<br/>class = 11>, fillcolor="#fef6fd"] ;
1 -> 13 ;
14 [label=<expert_1_1 &le; 0.474<br/>entropy = 2.855<br/>samples = 108<br/>value = [33, 1, 4, 2, 6, 1, 6, 1, 33, 4, 4, 1, 5, 7]<br/>class = 0>, fillcolor="#ffffff"] ;
13 -> 14 ;
15 [label=<expert_29_2 &le; 0.013<br/>entropy = 2.87<br/>samples = 67<br/>value = [28, 0, 4, 2, 3, 1, 6, 0, 4, 4, 2, 1, 5, 7]<br/>class = 0>, fillcolor="#f6d3ba"] ;
14 -> 15 ;
16 [label=<expert_0_3 &le; 0.011<br/>entropy = 2.451<br/>samples = 45<br/>value = [25, 0, 2, 2, 3, 1, 2, 0, 4, 1, 2, 1, 1, 1]<br/>class = 0>, fillcolor="#f2be9a"] ;
15 -> 16 ;
17 [label=<entropy = 1.154<br/>samples = 21<br/>value = [16, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0]<br/>class = 0>, fillcolor="#eca26d"] ;
16 -> 17 ;
18 [label=<entropy = 2.781<br/>samples = 24<br/>value = [9, 0, 0, 2, 3, 1, 0, 0, 4, 1, 1, 1, 1, 1]<br/>class = 0>, fillcolor="#f8e0ce"] ;
16 -> 18 ;
19 [label=<entropy = 2.504<br/>samples = 22<br/>value = [3, 0, 2, 0, 0, 0, 4, 0, 0, 3, 0, 0, 4, 6]<br/>class = 13>, fillcolor="#fce9e9"] ;
15 -> 19 ;
20 [label=<expert_5_2 &le; 0.265<br/>entropy = 1.474<br/>samples = 41<br/>value = [5, 1, 0, 0, 3, 0, 0, 1, 29, 0, 2, 0, 0, 0]<br/>class = 8>, fillcolor="#7b8eee"] ;
14 -> 20 ;
21 [label=<entropy = 1.923<br/>samples = 20<br/>value = [4, 1, 0, 0, 3, 0, 0, 0, 10, 0, 2, 0, 0, 0]<br/>class = 8>, fillcolor="#b5c0f5"] ;
20 -> 21 ;
22 [label=<entropy = 0.549<br/>samples = 21<br/>value = [1, 0, 0, 0, 0, 0, 0, 1, 19, 0, 0, 0, 0, 0]<br/>class = 8>, fillcolor="#4d67e8"] ;
20 -> 22 ;
23 [label=<expert_23_3 &le; 0.048<br/>entropy = 0.445<br/>samples = 41<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 38, 0, 2]<br/>class = 11>, fillcolor="#e748d5"] ;
13 -> 23 ;
24 [label=<entropy = 0.0<br/>samples = 25<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 25, 0, 0]<br/>class = 11>, fillcolor="#e539d1"] ;
23 -> 24 ;
25 [label=<entropy = 0.868<br/>samples = 16<br/>value = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 0, 2]<br/>class = 11>, fillcolor="#eb63db"] ;
23 -> 25 ;
26 [label=<expert_9_0 &le; 0.32<br/>entropy = 3.055<br/>samples = 241<br/>value = [5, 5, 1, 37, 34, 39, 7, 39, 2, 2, 33, 1, 35<br/>1]<br/>class = 5>, fillcolor="#ffffff"] ;
0 -> 26 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
27 [label=<expert_10_2 &le; 0.33<br/>entropy = 2.801<br/>samples = 167<br/>value = [4, 5, 1, 1, 32, 38, 7, 38, 1, 2, 31, 1, 5, 1]<br/>class = 5>, fillcolor="#ffffff"] ;
26 -> 27 ;
28 [label=<expert_3_3 &le; 0.485<br/>entropy = 2.304<br/>samples = 48<br/>value = [1, 5, 1, 1, 2, 0, 6, 1, 1, 1, 27, 1, 0, 1]<br/>class = 10>, fillcolor="#d89cf2"] ;
27 -> 28 ;
29 [label=<entropy = 3.136<br/>samples = 22<br/>value = [1, 5, 1, 1, 2, 0, 6, 1, 1, 1, 1, 1, 0, 1]<br/>class = 6>, fillcolor="#f3fdfd"] ;
28 -> 29 ;
30 [label=<entropy = 0.0<br/>samples = 26<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 26, 0, 0, 0]<br/>class = 10>, fillcolor="#b139e5"] ;
28 -> 30 ;
31 [label=<expert_1_1 &le; 3.664<br/>entropy = 2.157<br/>samples = 119<br/>value = [3, 0, 0, 0, 30, 38, 1, 37, 0, 1, 4, 0, 5, 0]<br/>class = 5>, fillcolor="#fdfffe"] ;
27 -> 31 ;
32 [label=<expert_1_1 &le; 0.593<br/>entropy = 2.029<br/>samples = 85<br/>value = [3.0, 0.0, 0.0, 0.0, 30.0, 37.0, 1.0, 4.0, 0.0, 1.0<br/>4.0, 0.0, 5.0, 0.0]<br/>class = 5>, fillcolor="#e6fcf2"] ;
31 -> 32 ;
33 [label=<expert_19_1 &le; 0.233<br/>entropy = 1.578<br/>samples = 35<br/>value = [3, 0, 0, 0, 24, 0, 1, 0, 0, 1, 3, 0, 3, 0]<br/>class = 4>, fillcolor="#7dee8a"] ;
32 -> 33 ;
34 [label=<entropy = 0.485<br/>samples = 19<br/>value = [0, 0, 0, 0, 17, 0, 0, 0, 0, 0, 2, 0, 0, 0]<br/>class = 4>, fillcolor="#50e862"] ;
33 -> 34 ;
35 [label=<entropy = 2.177<br/>samples = 16<br/>value = [3, 0, 0, 0, 7, 0, 1, 0, 0, 1, 1, 0, 3, 0]<br/>class = 4>, fillcolor="#c2f7c8"] ;
33 -> 35 ;
36 [label=<expert_2_3 &le; 0.821<br/>entropy = 1.279<br/>samples = 50<br/>value = [0, 0, 0, 0, 6, 37, 0, 4, 0, 0, 1, 0, 2, 0]<br/>class = 5>, fillcolor="#74edb6"] ;
32 -> 36 ;
37 [label=<entropy = 1.906<br/>samples = 16<br/>value = [0, 0, 0, 0, 4, 6, 0, 4, 0, 0, 0, 0, 2, 0]<br/>class = 5>, fillcolor="#defbee"] ;
36 -> 37 ;
38 [label=<expert_23_1 &le; 0.118<br/>entropy = 0.512<br/>samples = 34<br/>value = [0, 0, 0, 0, 2, 31, 0, 0, 0, 0, 1, 0, 0, 0]<br/>class = 5>, fillcolor="#4ce7a2"] ;
36 -> 38 ;
39 [label=<entropy = 0.0<br/>samples = 17<br/>value = [0, 0, 0, 0, 0, 17, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = 5>, fillcolor="#39e598"] ;
38 -> 39 ;
40 [label=<entropy = 0.834<br/>samples = 17<br/>value = [0, 0, 0, 0, 2, 14, 0, 0, 0, 0, 1, 0, 0, 0]<br/>class = 5>, fillcolor="#61eaad"] ;
38 -> 40 ;
41 [label=<expert_10_2 &le; 0.587<br/>entropy = 0.191<br/>samples = 34<br/>value = [0, 0, 0, 0, 0, 1, 0, 33, 0, 0, 0, 0, 0, 0]<br/>class = 7>, fillcolor="#3fa0e6"] ;
31 -> 41 ;
42 [label=<entropy = 0.337<br/>samples = 16<br/>value = [0, 0, 0, 0, 0, 1, 0, 15, 0, 0, 0, 0, 0, 0]<br/>class = 7>, fillcolor="#46a4e7"] ;
41 -> 42 ;
43 [label=<entropy = 0.0<br/>samples = 18<br/>value = [0, 0, 0, 0, 0, 0, 0, 18, 0, 0, 0, 0, 0, 0]<br/>class = 7>, fillcolor="#399de5"] ;
41 -> 43 ;
44 [label=<expert_24_0 &le; 0.472<br/>entropy = 1.651<br/>samples = 74<br/>value = [1, 0, 0, 36, 2, 1, 0, 1, 1, 0, 2, 0, 30, 0]<br/>class = 3>, fillcolor="#ebfbe4"] ;
26 -> 44 ;
45 [label=<expert_12_2 &le; 1.333<br/>entropy = 1.023<br/>samples = 42<br/>value = [0, 0, 0, 35, 2, 0, 0, 1, 1, 0, 1, 0, 2, 0]<br/>class = 3>, fillcolor="#87ea5c"] ;
44 -> 45 ;
46 [label=<entropy = 1.967<br/>samples = 16<br/>value = [0, 0, 0, 9, 2, 0, 0, 1, 1, 0, 1, 0, 2, 0]<br/>class = 3>, fillcolor="#b6f29c"] ;
45 -> 46 ;
47 [label=<entropy = 0.0<br/>samples = 26<br/>value = [0, 0, 0, 26, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br/>class = 3>, fillcolor="#6de539"] ;
45 -> 47 ;
48 [label=<expert_23_1 &le; 0.392<br/>entropy = 0.794<br/>samples = 32<br/>value = [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 28, 0]<br/>class = 12>, fillcolor="#e85396"] ;
44 -> 48 ;
49 [label=<entropy = 1.311<br/>samples = 16<br/>value = [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 12, 0]<br/>class = 12>, fillcolor="#ec6ea6"] ;
48 -> 49 ;
50 [label=<entropy = 0.0<br/>samples = 16<br/>value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0]<br/>class = 12>, fillcolor="#e53986"] ;
48 -> 50 ;
}